{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"inicio-notebook\"></a>\n",
    "# Proyecto End to End de Machine Learning \n",
    "### Viviendas en venta en Madrid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Librerías\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importación agrupada de librerías necesarias en este notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "# Añado el directorio padre (del que está este notebook) a sys.path\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from scripts.utils_agv import ini_inspec, crear_tabla_resumen, categoricas, numericas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"baseline\"></a> \n",
    "## 17. ¿Qué modelos? Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(viene del notebook anterior, el conjunto de datos 'test' aquí NUNCA llegan los datos de test) He guardado los dataframe a probar en formato parquet.\n",
    "\n",
    "Primero, importamos el parquet que queremos probar en todos nuestros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduzco aquí el Dataframe en cuestión \n",
    "file = 'train_sinOutliers_df5.parquet'\n",
    "file_path = f'../data/processed/{file}' \n",
    "df = pd.read_parquet(file_path, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente hago una separación de entrenamiento y validación, para evaluar mis modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['priceLog'], axis=1)  # Eliminamos la variable objetivo y variables no útiles\n",
    "y = df['priceLog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Tamaño del conjunto de validación: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Dummy (Baseline)\n",
    "dummy = DummyRegressor(strategy=\"mean\")\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en la escala logarítmica\n",
    "y_pred_dummy_log = dummy.predict(X_val)\n",
    "\n",
    "# Transformar los valores a la escala original\n",
    "y_val_original = np.expm1(y_val)  # Revertir log(price)\n",
    "y_pred_dummy_original = np.expm1(y_pred_dummy_log)\n",
    "\n",
    "# Evaluación con RMSE en la escala original\n",
    "rmse_dummy = np.sqrt(mean_squared_error(y_val_original, y_pred_dummy_original))\n",
    "print(f\"RMSE (escala original): {rmse_dummy:,.2f} €\")\n",
    "\n",
    "# Evaluación con MAPE en la escala original\n",
    "mape_dummy = mean_absolute_percentage_error(y_val_original, y_pred_dummy_original) * 100\n",
    "print(f\"MAPE (escala original): {mape_dummy:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "Ahora que tenemos un modelo muy básico de referencia, realizo mi Baseline con varios modelos para regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE modelos de regresión\n",
    "def evaluar_modelos(X_train, X_val, y_train, y_val, grafico_error=True):\n",
    "    \"\"\"\n",
    "    Evalúa múltiples modelos de regresión y devuelve métricas de error (RMSE y MAPE) en la escala original.\n",
    "    \n",
    "    Parámetros:\n",
    "        - X_train, X_val: Variables predictoras para entrenamiento y validación\n",
    "        - y_train, y_val: Variables objetivo en la escala logarítmica\n",
    "        - grafico_error (bool): Si es True, muestra los gráficos de comparación\n",
    "\n",
    "    Retorna:\n",
    "        - resultados (dict): Diccionario con las métricas de cada modelo\n",
    "    \"\"\"\n",
    "\n",
    "    # Definir modelos\n",
    "    modelos = {\n",
    "        'Regresión Lineal': LinearRegression(),\n",
    "        'Ridge': Ridge(),\n",
    "        'Lasso': Lasso(),\n",
    "        'Random Forest': RandomForestRegressor(random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "        'SVR': SVR(),\n",
    "        'Regresión Bayesiana': BayesianRidge()\n",
    "    }\n",
    "\n",
    "    resultados = {}\n",
    "\n",
    "    for nombre, modelo in modelos.items():\n",
    "        # Validación cruzada (CV) en la escala logarítmica\n",
    "        mse_cv = -cross_val_score(modelo, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "        rmse_cv = np.sqrt(mse_cv)\n",
    "\n",
    "        # Entrenamiento del modelo\n",
    "        modelo.fit(X_train, y_train)\n",
    "\n",
    "        # Predicciones en la escala logarítmica\n",
    "        y_pred_log = modelo.predict(X_val)\n",
    "\n",
    "        # Transformar a la escala original\n",
    "        y_val_original = np.expm1(y_val)\n",
    "        y_pred_original = np.expm1(y_pred_log)\n",
    "\n",
    "        # Evaluación en la escala original\n",
    "        rmse = np.sqrt(mean_squared_error(y_val_original, y_pred_original))\n",
    "        mape = mean_absolute_percentage_error(y_val_original, y_pred_original) * 100\n",
    "\n",
    "        # Guardar resultados\n",
    "        resultados[nombre] = {\n",
    "            'RMSE CV': rmse_cv.mean(),\n",
    "            'RMSE Val': rmse,\n",
    "            'MAPE Val': mape,\n",
    "            'Modelo': modelo\n",
    "        }\n",
    "\n",
    "        # Imprimir métricas\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"RMSE CV: {rmse_cv.mean():,.2f}\")\n",
    "        print(f\"RMSE val (original): {rmse:,.2f} €\")\n",
    "        print(f\"MAPE val (original): {mape:.2f} %\")\n",
    "\n",
    "    # Si grafico_error es True, mostramos las comparaciones gráficas\n",
    "    if grafico_error:\n",
    "        nombres_modelos = list(resultados.keys())\n",
    "        rmse_valores = [resultados[m]['RMSE Val'] for m in nombres_modelos]\n",
    "        mape_valores = [resultados[m]['MAPE Val'] for m in nombres_modelos]\n",
    "\n",
    "        plt.figure(figsize=(14, 6))\n",
    "\n",
    "        # Gráfico RMSE\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.barplot(x=nombres_modelos, y=rmse_valores)\n",
    "        plt.title('Comparación de RMSE por Modelo')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel('RMSE (Escala Original,€)')\n",
    "\n",
    "        # Gráfico MAPE\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.barplot(x=nombres_modelos, y=mape_valores)\n",
    "        plt.title('Comparación de MAPE por Modelo')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel('MAPE (%)')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return resultados\n",
    "\n",
    "# Uso de la función\n",
    "resultados_modelos = evaluar_modelos(X_train, X_val, y_train, y_val, grafico_error=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
